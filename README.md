# MS-Azure-ML-Capstone-Project

## Overview
This Capstone project is the final requisite in Udacity Microsoft Azure ML Nanodegree. In this project, we work with a dataset of our choice to solve a Machine Learning problem using two approaches in Azure ML - AutoML and Hyperdrive. Finally the best model, out of both is chosen, deployed and consumed.

For this project, I chose to work on a breast Cancer prediction dataset. Research shows that Prediction models based on these predictors, if accurate, can potentially be used as a biomarker of breast cancer. This could be used in developing easy to use applications that use Machine learning techniques to predict the existence of cancer and take steps in a timely manner.


## Dataset Overview:

The dataset that I chose was from UCI website on Breast Cancer.
The link for it is available [here: ](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra)

There are 10 predictors, all quantitative, and a binary dependent variable (‘Classification’), indicating the presence  (denoted by 1) or absence (denoted by 0) of breast cancer.

The predictors below are parameters that can be gathered in routine blood analysis:

- **Age (years)**
- **BMI (kg/m2)**
- **Glucose (mg/dL)**
- **Insulin (µU/mL)**
- **HOMA**
- **Leptin (ng/mL)**
- **Adiponectin (µg/mL)**
- **Resistin (ng/mL)**
- **MCP-1(pg/dL**
- **Labels:**
 1=Healthy controls 
 2=Patients

### Access
The dataset is accessed directly from UCI website using Azure's TabularDatasetFactory and registerd in the Workspace.

### Task
The problem is to predict the presence of breast cancer.  This is a classification problem (1: yes, 0: no cancer). To achieve this, we will be using two approaches and compare both using AUC (Area Under the Curve) as the Primary Metric.


## Automated ML

AutomatedML configuration used for automl tasks for this experiment is as follows:
Configration | Value
------------ | ------------- 
1. The task: Classification
2. The primary metric: AUC_Weighted
3. No of cross_validations: 5
4. Experiment timeouts after 15 mins
5. Concurrent iteration is used: 10
6. Experiment_timeout_minutes: 15
 
 
## Results
 
The below snapshot shows different models generated by automl feature.

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/votingEnsemble_best_model.png)
 
The best model was a Voting Ensemble that had an AUC of 84%
 
![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/automl_best_model_metrics_summary.png)
 
 Area under the Curve (AUC) is maximum for the best model:
 
![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/best_model_prc_and_roc-curve.png)
 
The Best Run ID was:
 
![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/best_run_ID.png)
 
The best model run screenshot :

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/best_run_model.png)
 
 
 
## HyperParameter Tuning
I used **Random Parameter Sampling** to sample over a discrete set of values. With this sampling algorithm, AzureML provides flexibility for us to choose hyperparameter values from a set of discrete values or over a continuous range of values. 

In this instance, I chose **Logistic Regression** as it is a well-known model for classification. The three parameters used for training my model were:

- **C (The inverse regularization strength):** Uniformly distributed between a range of 0.0 and 1.0. I chose a continuous C rather than hard fixed values of C for more flexibility for the mode.
- **max_iter(Maximum iteration to converge):** 50,100,150,200,250
- **Solver:** Choice between these solvers: ‘liblinear', 'sag', 'lbfgs', 'saga'

T**BanditPolicy** is used for computational efficiency in order to terminate runs if the primary metric is not within a specified slack factor/slack amount. I used an evaluation interval of 2, slack_factor of 0.2, and delay_evaluation interval of 5.

## Results

The Hyperdrive Run Details are below:

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/Hyperparameter/Run_Details.png)
 
The best model had an AUC score  of 77%

And the parameters were: Best Solver: ‘lbfgs’ C: 0.127 and  Max iterations: 150

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/Hyperparameter/Best_model_metrics.png)
 
The different models that were created:

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/Hyperparameter/child_runs.png)

The 3d chart for different models. The best model has the optimum balance of C, max-iter and solver:

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/Hyperparameter/3d_chart_best_model_metrics.png)

## Model  Deployment

As it has been observed that AUC score of AutoML generated model was 84% much higher than AUC score (77%) of model generated by Hyperdrive.
Hence I decided to Deploy the AutoML Model.

Model getting deployed in the Jupyter Notebook:

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/ACI_creation_succeeded.png)

Screenshots of deployed model in ML studio:

Endpoints

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/Deployed_model_healthy.png)

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/Deployed_model_app_insights_link.png)

Application Insights Analysis

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/Deployed_model_application_insights.png)

Webservice Logs are enabled and can also be seen in the notebook itself.

![image](https://github.com/jyotisood/MS-Azure-ML-Capstone-Project/blob/main/AutoML/webservice-logs.png)

### Screencast Link
Screencast is available [here:](https://vimeo.com/511275482)

## Standout Suggestions
Enabled Application Insights which help in logging and monitoring of web service

## Future work
- To try and tweak the parameters like C and max-iter to see how well it compares with automl. Maybe try some other classifier than Logistic Regression.
- Learn conversion of a registered model to ONNX format.
 


**References:**
[Patricio, 2018] Patrício, M., Pereira, J., Crisóstomo, J., Matafome, P., Gomes, M., Seiça, R., & Caramelo, F. (2018). Using Resistin, glucose, age and BMI to predict the presence of breast cancer. BMC Cancer, 18(1).
